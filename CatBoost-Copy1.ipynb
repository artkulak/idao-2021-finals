{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49112cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# IMPORT LIBS\n",
    "#####################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scoring import local_scorer\n",
    "import scipy\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#####################\n",
    "# SET CONSTANTS\n",
    "#####################\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "OUTPUT_PATH = Path('../output')\n",
    "TRAIN_PATH = INPUT_PATH \n",
    "\n",
    "TARGET_COLUMNS = ['sale_flg', 'sale_amount', 'contacts']\n",
    "FIXED_SEEDS = [948, 534, 432, 597, 103, 21, 2242, 17, 20, 29]\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "USE_WANDB = False\n",
    "CURRENT_TIME = str(datetime.datetime.now()).replace(' ', '_').split('.')[0]\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b574c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Config\n",
    "###############\n",
    "\n",
    "n_seed = 5\n",
    "n_fold = 3\n",
    "retrain_after_valid = True\n",
    "make_submission = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83812efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=\"idao-2021-finals\", name = f'{CURRENT_TIME}') # todo add config here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3242b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "\n",
    "# transactions = pd.read_csv(INPUT_PATH / 'trxn.csv')\n",
    "# assets_under_management = pd.read_csv(INPUT_PATH / 'aum.csv')\n",
    "# balance = pd.read_csv(INPUT_PATH / 'balance.csv')\n",
    "# client = pd.read_csv(INPUT_PATH / 'client.csv')\n",
    "# campaigns = pd.read_csv(INPUT_PATH / 'com.csv')\n",
    "# deals = pd.read_csv(INPUT_PATH / 'deals.csv')\n",
    "# dict_merchant_category_code = pd.read_csv(INPUT_PATH / 'dict_mcc.csv')\n",
    "# payments = pd.read_csv(INPUT_PATH / 'payments.csv')\n",
    "# funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "# appl = pd.read_csv(INPUT_PATH / 'appl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a15f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_total(df, col_name):\n",
    "    return data['client_id'].map(df.groupby(['client_id', col_name]).size().index.get_level_values('client_id').value_counts()).fillna(0)\n",
    "\n",
    "\n",
    "def get_feature_most_common(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: scipy.stats.mode(x)[0][0])).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_max(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].max()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_min(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].min()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_mean(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].mean()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_std(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].std()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_max_min(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: x.max() - x.min())).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_timedelta(df, col_name):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: (x.max() - x.min()).days)).fillna(-1)\n",
    "\n",
    "\n",
    "def get_feature_diff(df, col_name1, col_name2, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name1].sum() - df.groupby('client_id')[col_name2].sum()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_rate(df, col_name1, col_name2, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name1].sum() / (df.groupby('client_id')[col_name2].sum() + 1e-12)).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def create_features_transactions(data):\n",
    "    \n",
    "    transactions = pd.read_csv(INPUT_PATH / 'trxn.csv')\n",
    "    dict_merchant_category_code = pd.read_csv(INPUT_PATH / 'dict_mcc.csv')\n",
    "    \n",
    "    transactions['mcc_cd'] = transactions['mcc_cd'].fillna(-2)\n",
    "    transactions['txn_city'] = transactions['txn_city'].fillna('<UNK>')\n",
    "    transactions['tsp_name'] = transactions['tsp_name'].fillna('<UNK>')\n",
    "    transactions['txn_comment_2'] = transactions['txn_comment_2'].fillna('<UNK>')\n",
    "\n",
    "    transactions = transactions.merge(dict_merchant_category_code, on='mcc_cd', how='left')\n",
    "    del dict_merchant_category_code\n",
    "    transactions['brs_mcc_group'] = transactions['brs_mcc_group'].fillna('<UNK>')\n",
    "    transactions['brs_mcc_subgroup'] = transactions['brs_mcc_subgroup'].fillna('<UNK>')\n",
    "    \n",
    "    data['total_transactions'] = data['client_id'].map(transactions.groupby('client_id').size()).fillna(0)\n",
    "#     data['total_transactions_cards'] = get_feature_total(transactions, 'card_id')\n",
    "\n",
    "#     data['total_transaction_amount'] = data['client_id'].map(transactions.groupby('client_id')['tran_amt_rur'].sum()).fillna(0) # add monthly, daily, etc\n",
    "    data['mean_transaction_amt'] = get_feature_mean(transactions, 'tran_amt_rur', -1) # add monthly, daily, etc\n",
    "    data['std_transaction_amount'] = get_feature_std(transactions, 'tran_amt_rur', -1) # add monthly, daily, etc\n",
    "    \n",
    "    data['total_transactions_mcc_cd'] = get_feature_total(transactions, 'mcc_cd')\n",
    "#     data['total_transactions_share_mcc_cd'] = (data['total_transactions_mcc_cd'] / data['total_transactions']).fillna(0)\n",
    "#     data['most_common_transactions_mcc_cd'] = get_feature_most_common(transactions, 'mcc_cd', -1)\n",
    "    \n",
    "    data['total_transactions_merchant_cd'] = get_feature_total(transactions, 'merchant_cd')\n",
    "    data['total_share_transactions_merchant_cd'] = (data['total_transactions_merchant_cd'] / data['total_transactions']).fillna(0)\n",
    "#     data['most_common_transactions_merchant_cd'] = get_feature_most_common(transactions, 'merchant_cd', -1)\n",
    "    \n",
    "    data['total_transactions_txn_city'] = get_feature_total(transactions, 'txn_city')\n",
    "    data['total_share_transactions_txn_city'] = (data['total_transactions_txn_city'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_transactions_txn_city'] = get_feature_most_common(transactions, 'txn_city', '<unknown>')\n",
    "    \n",
    "    data['total_transactions_tsp_name'] = get_feature_total(transactions, 'tsp_name')\n",
    "    data['total_share_transactions_tsp_name'] = (data['total_transactions_tsp_name'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_transactions_tsp_name'] = get_feature_most_common(transactions, 'tsp_name', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_txn_comment_1'] = get_feature_total(transactions, 'txn_comment_1')\n",
    "#     data['most_common_transactions_txn_comment_1'] = get_feature_most_common(transactions, 'txn_comment_1', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_txn_comment_2'] = get_feature_total(transactions, 'txn_comment_2')\n",
    "#     data['most_common_transactions_txn_comment_2'] = get_feature_most_common(transactions, 'txn_comment_2', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_brs_mcc_group'] = get_feature_total(transactions, 'brs_mcc_group')\n",
    "#     data['most_common_transactions_brs_mcc_group'] = get_feature_most_common(transactions, 'brs_mcc_group', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_brs_mcc_subgroup'] = get_feature_total(transactions, 'brs_mcc_subgroup')\n",
    "#     data['most_common_transactions_brs_mcc_subgroup'] = get_feature_most_common(transactions, 'brs_mcc_subgroup', '<unknown>')\n",
    "    \n",
    "    del transactions\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_aum(data):\n",
    "    \n",
    "    assets_under_management = pd.read_csv(INPUT_PATH / 'aum.csv')\n",
    "    \n",
    "#     data['total_aum'] = data['client_id'].map(assets_under_management.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_aum_product_code'] = get_feature_total(assets_under_management, 'product_code')\n",
    "#     data['most_common_aum_product_code'] = get_feature_most_common(assets_under_management, 'product_code', '<unknown>').value_counts()\n",
    "    \n",
    "    data['mean_aum_balance_rur_amt'] = get_feature_mean(assets_under_management, 'balance_rur_amt', -1)\n",
    "    data['std_aum_balance_rur_amt'] = get_feature_std(assets_under_management, 'balance_rur_amt', -1)\n",
    "    data['max_min_aum_balance_rur_amt'] = get_feature_max_min(assets_under_management, 'balance_rur_amt', -1)\n",
    "    \n",
    "    del assets_under_management\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_balance(data):\n",
    "    \n",
    "    balance = pd.read_csv(INPUT_PATH / 'balance.csv')\n",
    "    \n",
    "    balance['crncy_cd'] = balance['crncy_cd'].fillna(-2)\n",
    "    balance['prod_cat_name'] = balance['prod_cat_name'].fillna('<UNK>')\n",
    "    balance['prod_group_name'] = balance['prod_group_name'].fillna('<UNK>')\n",
    "    \n",
    "    data['total_balance'] = data['client_id'].map(balance.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_balance_crncy_cd'] = get_feature_total(balance, 'crncy_cd')\n",
    "#     data['most_common_balance_crncy_cd'] = get_feature_most_common(balance, 'crncy_cd', -1)\n",
    "    \n",
    "#     data['total_balance_eop_bal_sum_rur'] = get_feature_total(balance, 'eop_bal_sum_rur')\n",
    "    data['total_share_balance_eop_bal_sum_rur'] = (get_feature_total(balance, 'eop_bal_sum_rur') / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_eop_bal_sum_rur'] = get_feature_mean(balance, 'eop_bal_sum_rur', -9999)\n",
    "    data['std_balance_eop_bal_sum_rur'] = get_feature_std(balance, 'eop_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_balance_min_bal_sum_rur'] = get_feature_total(balance, 'min_bal_sum_rur')\n",
    "    data['total_share_balance_min_bal_sum_rur'] = (data['total_balance_min_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_min_bal_sum_rur'] = get_feature_mean(balance, 'min_bal_sum_rur', -9999)\n",
    "    data['std_balance_min_bal_sum_rur'] = get_feature_std(balance, 'min_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_balance_max_bal_sum_rur'] = get_feature_total(balance, 'max_bal_sum_rur')\n",
    "    data['total_share_balance_max_bal_sum_rur'] = (data['total_balance_max_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_max_bal_sum_rur'] = get_feature_mean(balance, 'max_bal_sum_rur', -9999)\n",
    "#     data['std_balance_max_bal_sum_rur'] = get_feature_std(balance, 'max_bal_sum_rur', -9999)\n",
    "    \n",
    "#     data['total_balance_avg_bal_sum_rur'] = get_feature_total(balance, 'avg_bal_sum_rur')\n",
    "    data['total_share_balance_avg_bal_sum_rur'] = (get_feature_total(balance, 'avg_bal_sum_rur') / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_avg_bal_sum_rur'] = get_feature_mean(balance, 'avg_bal_sum_rur', -9999)\n",
    "#     data['std_balance_avg_bal_sum_rur'] = get_feature_std(balance, 'avg_bal_sum_rur', -9999)\n",
    "    data['max_min_balance_avg_bal_sum_rur'] = get_feature_max_min(balance, 'avg_bal_sum_rur', -9999)\n",
    "    \n",
    "#     data['total_balance_prod_cat_name'] = get_feature_total(balance, 'prod_cat_name')\n",
    "#     data['most_common_balance_prod_cat_name'] = get_feature_most_common(balance, 'prod_cat_name', '<unknown>')\n",
    "    \n",
    "    data['total_balance_prod_group_name'] = get_feature_total(balance, 'prod_group_name')\n",
    "#     data['most_common_balance_prod_group_name'] = get_feature_most_common(balance, 'prod_group_name', '<unknown>')\n",
    "    \n",
    "    del balance\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_client(data):\n",
    "    \n",
    "    client = pd.read_csv(INPUT_PATH / 'client.csv')\n",
    "    \n",
    "    client = client.rename(columns={\n",
    "        'gender': 'client_gender',\n",
    "        'age': 'client_age',\n",
    "        'region': 'client_region',\n",
    "        'city': 'client_city',\n",
    "        'citizenship': 'client_citizenship',\n",
    "        'education': 'client_education',\n",
    "        'job_type': 'client_job_type'\n",
    "    })\n",
    "    \n",
    "    data = data.merge(client, on='client_id')\n",
    "#     data['match_client_region-region_cd'] = (data['client_region'] == data['region_cd']).astype(int)\n",
    "    data = data.drop(['client_citizenship', 'client_job_type', 'client_gender'], axis=1)\n",
    "    \n",
    "    del client\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_campaigns(data):\n",
    "\n",
    "    campaigns = pd.read_csv(INPUT_PATH / 'com.csv')\n",
    "    \n",
    "    campaigns['prod'] = campaigns['prod'].fillna('<UNK>')\n",
    "    \n",
    "    data['total_campaigns'] = data['client_id'].map(campaigns.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_campaigns_agr_flg'] = get_feature_total(campaigns, 'agr_flg')\n",
    "    data['mean_campaigns_agr_flg'] = get_feature_mean(campaigns, 'agr_flg', -1)\n",
    "    \n",
    "#     data['total_campaigns_otkaz'] = get_feature_total(campaigns, 'otkaz')\n",
    "    data['mean_campaigns_otkaz'] = get_feature_mean(campaigns, 'otkaz', -1)\n",
    "    \n",
    "#     data['total_campaigns_dumaet'] = get_feature_total(campaigns, 'dumaet')\n",
    "    data['mean_campaigns_dumaet'] = get_feature_mean(campaigns, 'dumaet', -1)\n",
    "    \n",
    "#     data['total_campaigns_ring_up_flg'] = get_feature_total(campaigns, 'ring_up_flg')\n",
    "#     data['most_common_campaigns_ring_up_flg'] = get_feature_most_common(campaigns, 'ring_up_flg', -1)\n",
    "    \n",
    "#     data['total_campaigns_count_comm'] = get_feature_total(campaigns, 'count_comm')\n",
    "#     data['most_common_campaigns_count_comm'] = get_feature_most_common(campaigns, 'count_comm', -1)\n",
    "    \n",
    "#     data['total_campaigns_channel'] = get_feature_total(campaigns, 'channel')\n",
    "#     data['most_common_campaigns_channel'] = get_feature_most_common(campaigns, 'channel', '<unknown>')\n",
    "    \n",
    "#     data['total_campaigns_prod'] = get_feature_total(campaigns, 'prod')\n",
    "    data['most_common_campaigns_prod'] = get_feature_most_common(campaigns, 'prod', '<unknown>')\n",
    "    \n",
    "#     data['diff_campaigns_otkaz-agr_flg'] = get_feature_diff(campaigns, 'otkaz', 'agr_flg', -999)\n",
    "    \n",
    "    data['rate_campaigns_otkaz-count_comm'] = get_feature_rate(campaigns, 'otkaz', 'count_comm', -999)\n",
    "    data['rate_campaigns_agr_flg-count_comm'] = get_feature_rate(campaigns, 'agr_flg', 'count_comm', -999)\n",
    "    data['rate_campaigns_not_ring_up_flg-count_comm'] = get_feature_rate(campaigns, 'not_ring_up_flg', 'count_comm', -999)\n",
    "    data['rate_campaigns_ring_up_flg-count_comm'] = get_feature_rate(campaigns, 'ring_up_flg', 'count_comm', -999)\n",
    "    \n",
    "    del campaigns\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_deals(data):\n",
    "    \n",
    "    deals = pd.read_csv(INPUT_PATH / 'deals.csv')\n",
    "    \n",
    "    deals['crncy_cd'] = deals['crncy_cd'].fillna(-2)\n",
    "    deals['agrmnt_rate_active'] = deals['agrmnt_rate_active'].fillna(-2)\n",
    "    deals['agrmnt_rate_passive'] = deals['agrmnt_rate_passive'].fillna(-2)\n",
    "    deals['agrmnt_sum_rur'] = deals['agrmnt_sum_rur'].fillna(-2)\n",
    "    deals['prod_type_name'] = deals['prod_type_name'].fillna('<UNK>')\n",
    "    deals['argmnt_close_start_days'] = (pd.to_datetime(deals['agrmnt_close_dt']) - pd.to_datetime(deals['agrmnt_start_dt'])).dt.days.fillna(-2)\n",
    "    \n",
    "    data['total_deals'] = data['client_id'].map(deals.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_deals_crncy_cd'] = get_feature_total(deals, 'crncy_cd')\n",
    "#     data['most_common_deals_crncy_cd'] = get_feature_most_common(deals, 'crncy_cd', -1)\n",
    "    \n",
    "    data['total_deals_agrmnt_rate_active'] = get_feature_total(deals, 'agrmnt_rate_active')\n",
    "    data['max_deals_agrmnt_rate_active'] = get_feature_max(deals, 'agrmnt_rate_active', -1)\n",
    "    \n",
    "#     data['total_deals_agrmnt_rate_passive'] = get_feature_total(deals, 'agrmnt_rate_passive')\n",
    "    data['max_deals_agrmnt_rate_passive'] = get_feature_max(deals, 'agrmnt_rate_passive', -1)\n",
    "    \n",
    "    data['total_deals_agrmnt_sum_rur'] = get_feature_total(deals, 'agrmnt_sum_rur')\n",
    "    data['mean_deals_agrmnt_sum_rur'] = get_feature_mean(deals, 'agrmnt_sum_rur', -1)\n",
    "    data['std_deals_agrmnt_sum_rur'] = get_feature_std(deals, 'agrmnt_sum_rur', -1)\n",
    "    \n",
    "    data['total_deals_prod_type_name'] = get_feature_total(deals, 'prod_type_name')\n",
    "    data['most_common_deals_prod_type_name'] = get_feature_most_common(deals, 'prod_type_name', '<unknown>')\n",
    "    \n",
    "    data['total_deals_argmnt_close_start_days'] = get_feature_total(deals, 'argmnt_close_start_days')\n",
    "    data['max_deals_argmnt_close_start_days'] = get_feature_max(deals, 'argmnt_close_start_days', -1)\n",
    "#     data['min_deals_argmnt_close_start_days'] = get_feature_min(deals, 'argmnt_close_start_days', -1)\n",
    "    data['mean_deals_argmnt_close_start_days'] = get_feature_mean(deals, 'argmnt_close_start_days', -1)\n",
    "    data['std_deals_argmnt_close_start_days'] = get_feature_std(deals, 'argmnt_close_start_days', -1)\n",
    "    \n",
    "    del deals\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_payments(data):\n",
    "    \n",
    "    payments = pd.read_csv(INPUT_PATH / 'payments.csv')\n",
    "    \n",
    "    payments['day_dt'] = pd.to_datetime(payments['day_dt'])\n",
    "    \n",
    "    data['total_payments'] = data['client_id'].map(payments.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "    data['mean_payments_sum_rur'] = get_feature_mean(payments, 'sum_rur', -1)\n",
    "    data['std_payments_sum_rur'] = get_feature_std(payments, 'sum_rur', -1)\n",
    "    data['min_payments_sum_rur'] = get_feature_min(payments, 'sum_rur', -1)\n",
    "    data['max_payments_sum_rur'] = get_feature_max(payments, 'sum_rur', -1)\n",
    "    \n",
    "#     data['total_payments_pmnts_name'] = get_feature_total(payments, 'pmnts_name')\n",
    "#     data['most_common_payments_pmnts_name'] = get_feature_most_common(payments, 'pmnts_name', '<unknown>')\n",
    "    \n",
    "    # payments \n",
    "#     data['last_known_salary'] = data['client_id'].map(payments.groupby('client_id').apply(lambda x: x['sum_rur'].iloc[0])).fillna(-1)\n",
    "#     data['total_recieved_salary'] = data['client_id'].map(payments.groupby('client_id').apply(lambda x: x['sum_rur'].sum())).fillna(-1)\n",
    "    \n",
    "    data['timedelta_payments_day_dt'] = get_feature_timedelta(payments, 'day_dt')\n",
    "    \n",
    "    del payments\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_appl(data):\n",
    "    \n",
    "    appl = pd.read_csv(INPUT_PATH / 'appl.csv')\n",
    "    \n",
    "    appl['appl_stts_name_dc'] = appl['appl_stts_name_dc'].fillna('<UNK>')\n",
    "    appl['appl_sale_channel_name'] = appl['appl_sale_channel_name'].fillna('<UNK>')\n",
    "    appl['month_end_dt'] = pd.to_datetime(appl['month_end_dt'])\n",
    "    \n",
    "    data['total_appl'] = data['client_id'].map(appl.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_appl_prod_group_name'] = get_feature_total(appl, 'appl_prod_group_name')\n",
    "#     data['most_common_appl_prod_group_name'] = get_feature_most_common(appl, 'appl_prod_group_name', '<unknown>')\n",
    "    \n",
    "    data['total_appl_prod_type_name'] = get_feature_total(appl, 'appl_prod_type_name')\n",
    "    data['most_common_appl_prod_type_name'] = get_feature_most_common(appl, 'appl_prod_type_name', '<unknown>')\n",
    "    \n",
    "#     data['total_appl_stts_name_dc'] = get_feature_total(appl, 'appl_stts_name_dc')\n",
    "#     data['most_common_appl_stts_name_dc'] = get_feature_most_common(appl, 'appl_stts_name_dc', '<unknown>')\n",
    "    \n",
    "#     data['total_appl_sale_channel_name'] = get_feature_total(appl, 'appl_sale_channel_name')\n",
    "#     data['most_common_appl_sale_channel_name'] = get_feature_most_common(appl, 'appl_sale_channel_name', '<unknown>')\n",
    "    \n",
    "    data['timedelta_appl_month_end_dt'] = get_feature_timedelta(appl, 'month_end_dt')\n",
    "    \n",
    "    del appl\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_funnel(data):\n",
    "    \n",
    "    data = data.drop('feature_7', axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeba4986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 426 ms, total: 33 s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create features\n",
    "\n",
    "funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "\n",
    "data = funnel.copy()\n",
    "\n",
    "del funnel\n",
    "\n",
    "data = create_features_transactions(data)\n",
    "data = create_features_aum(data)\n",
    "data = create_features_balance(data)\n",
    "data = create_features_client(data)\n",
    "data = create_features_campaigns(data)\n",
    "data = create_features_deals(data)\n",
    "data = create_features_payments(data)\n",
    "data = create_features_appl(data)\n",
    "data = create_features_funnel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dc1118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill_cols = ['gender', 'citizenship', 'education', 'job_type', 'most_common_txn_city', 'most_common_tsp_name', 'most_common_txn_comment_1', 'most_common_txn_comment_2']# 'most_common_txn_city', 'most_common_tsp_name', 'most_common_txn_comment_1', 'most_common_txn_comment_2']\n",
    "for c in data.columns:\n",
    "    col_type = data[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        data[c] = data[c].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4308e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = TARGET_COLUMNS + ['client_id'])\n",
    "Y = data[TARGET_COLUMNS[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4520d8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87049e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    os.mkdir(OUTPUT_PATH / 'models')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'models')\n",
    "    os.mkdir(OUTPUT_PATH / 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ac95a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats =[]\n",
    "for c in X.columns:\n",
    "    col_type = X[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        X[c] = X[c].astype(str)\n",
    "        cat_feats.append(np.argwhere(X.columns == c)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfdf7b",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4b08468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from quick_hyperopt import quick_hyperopt\n",
    "# cb_params = quick_hyperopt(X, Y, 'cb', 10, cat_features = cat_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcba92",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a43048e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_train(X_train, Y_train, X_val, Y_val, i_fold=None, seed=None, params = None):\n",
    "    # prepare for train\n",
    "    \n",
    "    params = {\n",
    "              \"thread_count\":-1,\n",
    "              \"random_seed\": seed,\n",
    "#               \"one_hot_max_size\": 5\n",
    "#               \"learning_rate\": 0.05,\n",
    "#               \"boosting_type\":\"Plain\",\n",
    "#               \"leaf_estimation_iterations\":1,\n",
    "#               \"iterations\": 200,\n",
    "#               \"random_strength\": 2,\n",
    "#               \"depth\": 7,\n",
    "#               \"l2_leaf_reg\": 1,\n",
    "#               \"eval_metric\": 'F1',\n",
    "#               'verbose': 10\n",
    "#         'objective': 'quantile',\n",
    "              }\n",
    "    \n",
    "    \n",
    "    #model = LGBMRegressor(**params) # define model here\n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    \n",
    "    # Fit and save model\n",
    "    \n",
    "    if X_val is None:\n",
    "        model.fit(X_train, Y_train, verbose=False, cat_features=cat_feats)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train,   eval_set=(X_val, Y_val), early_stopping_rounds=500, verbose=False, cat_features=cat_feats)\n",
    "    #joblib.dump(model, OUTPUT_PATH / 'models' / f'catboost_{i_fold}_{seed}_{CURRENT_TIME}.pkl')\n",
    "    model.save_model(OUTPUT_PATH / 'models' / f'catboost_{i_fold}_{seed}_{CURRENT_TIME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1d903a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 948, 1/5\n",
      "Seed: 534, 2/5\n",
      "Seed: 432, 3/5\n",
      "Seed: 597, 4/5\n",
      "Seed: 103, 5/5\n",
      "CPU times: user 45min 25s, sys: 5min 40s, total: 51min 6s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof = np.zeros((X.shape[0], n_seed)) # cv_score\n",
    "seeds = []\n",
    "for i_seed in range(n_seed):\n",
    "    seed = FIXED_SEEDS[i_seed]\n",
    "    seed_everything(seed)\n",
    "\n",
    "    seeds.append(seed)\n",
    "    print('Seed: {}, {}/{}'.format(seed, i_seed + 1, n_seed))\n",
    "    \n",
    "    if n_fold != 1:\n",
    "        kf = KFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "        split_indexes = kf.split(X, Y)\n",
    "    else:\n",
    "        split_indexes = [train_test_split(np.arange(X.shape[0]), random_state=seed, shuffle = True)]\n",
    "    \n",
    "    for i_fold, (train_idx, val_idx) in enumerate(split_indexes):\n",
    "#         print(\"# Fold: {}/{} (seed: {}/{})\".format(i_fold + 1, n_fold, i_seed + 1, n_seed))\n",
    "\n",
    "        # dataset\n",
    "        X_train, Y_train = X.iloc[train_idx], Y[train_idx]\n",
    "        X_val, Y_val = X.iloc[val_idx], Y[val_idx]\n",
    "\n",
    "\n",
    "        # train\n",
    "        running_train(X_train, Y_train, X_val, Y_val, i_fold=i_fold, seed=seed)\n",
    "\n",
    "        # predict on oof\n",
    "#         print('predict on oof...', end='')\n",
    "        model = CatBoostClassifier(thread_count=-1)\n",
    "        model.load_model( OUTPUT_PATH / 'models' / f'catboost_{i_fold}_{seed}_{CURRENT_TIME}')\n",
    "\n",
    "        prediction = model.predict_proba(X_val)[:, 1]\n",
    "        #prediction = model.predict(X_val)\n",
    "        \n",
    "        oof[val_idx, i_seed] = prediction\n",
    "#         print('  done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_threshold = 0.16\n",
    "funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "if n_fold != 1:\n",
    "    Y_predicted = (np.mean(oof, axis = 1) > prediction_threshold).astype(int)\n",
    "    Y_test = funnel[['client_id', 'sale_flg']].set_index('client_id')\n",
    "    test_funnel =  funnel.set_index('client_id')\n",
    "if n_fold == 1 and n_seed == 1:\n",
    "    Y_predicted = (prediction > prediction_threshold).astype(int)\n",
    "    Y_test = funnel[['client_id', 'sale_flg']].iloc[split_indexes[0][1]].set_index('client_id')\n",
    "    test_funnel = funnel.iloc[split_indexes[0][1]].set_index('client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19350fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir(OUTPUT_PATH / 'scoring')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'scoring')\n",
    "    os.mkdir(OUTPUT_PATH / 'scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6030d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/home/jupyter/idao-2021-finals/scoring/scorer.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected['gain'] = selected[SALE_FLAG] * selected[SALE_AMOUNT].fillna(0) - selected[CONTACTS] * CALL_COST\n"
     ]
    }
   ],
   "source": [
    "public_score, private_score = local_scorer.get_score(test_funnel, Y_predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "741a26a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public ANIC 5442.573297516055 Private ANIC 5818.76932737929\n",
      "ANIC 5693.370650758212\n",
      "Precision 0.5038701994641263 | Recall 0.9619210002841716 | F1 0.6613265605157762\n"
     ]
    }
   ],
   "source": [
    "validation_precision = precision_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_recall = recall_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_f1 = f1_score(Y_test['sale_flg'], Y_predicted)\n",
    "print(f'Public ANIC {public_score} Private ANIC {private_score}')\n",
    "print(f'ANIC {1/3*public_score+ 2/3 * private_score}')\n",
    "print(f'Precision {validation_precision} | Recall {validation_recall} | F1 {validation_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915ac43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc7edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5374321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2497d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1f202b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public ANIC 5433.519104102716 Private ANIC 5765.939118755233\n",
      "ANIC 5655.132447204393\n",
      "Precision 0.5019345238095239 | Recall 0.9585109406081274 | F1 0.6588534036527005\n"
     ]
    }
   ],
   "source": [
    "validation_precision = precision_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_recall = recall_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_f1 = f1_score(Y_test['sale_flg'], Y_predicted)\n",
    "print(f'Public ANIC {public_score} Private ANIC {private_score}')\n",
    "print(f'ANIC {1/3*public_score+ 2/3 * private_score}')\n",
    "print(f'Precision {validation_precision} | Recall {validation_recall} | F1 {validation_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37e6d31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imp</th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>most_common_transactions_tsp_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.035893</td>\n",
       "      <td>total_aum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.083819</td>\n",
       "      <td>total_balance_avg_bal_sum_rur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.095239</td>\n",
       "      <td>std_balance_max_bal_sum_rur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.095668</td>\n",
       "      <td>feature_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.129237</td>\n",
       "      <td>total_transactions_share_mcc_cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.189961</td>\n",
       "      <td>std_payments_sum_rur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.192257</td>\n",
       "      <td>rate_campaigns_ring_up_flg-count_comm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.197795</td>\n",
       "      <td>mean_campaigns_otkaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.203084</td>\n",
       "      <td>total_balance_max_bal_sum_rur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         imp                                    col\n",
       "24       0.0      most_common_transactions_tsp_name\n",
       "25  0.035893                              total_aum\n",
       "41  0.083819          total_balance_avg_bal_sum_rur\n",
       "40  0.095239            std_balance_max_bal_sum_rur\n",
       "7   0.095668                              feature_7\n",
       "16  0.129237        total_transactions_share_mcc_cd\n",
       "74  0.189961                   std_payments_sum_rur\n",
       "58  0.192257  rate_campaigns_ring_up_flg-count_comm\n",
       "52  0.197795                   mean_campaigns_otkaz\n",
       "37  0.203084          total_balance_max_bal_sum_rur"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([model.get_feature_importance(), X_train.columns], index=['imp', 'col']).T.sort_values('imp')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d66b5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_after_valid = False\n",
    "if retrain_after_valid:\n",
    "    running_train(X, Y, None, None, i_fold=-1, seed=4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f421befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.run.summary[\"validation_f1\"] = validation_f1\n",
    "    wandb.run.summary[\"anic\"] = 1/3*public_score+ 2/3 * private_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ee5858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 5800.68066785\n"
     ]
    }
   ],
   "source": [
    "make_submission = True\n",
    "if make_submission:\n",
    "    public_anic = float(input())\n",
    "    wandb.run.summary[\"public_anic\"] = public_anic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38468822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3883<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.44MB of 0.44MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/idao-2021-finals/wandb/run-20210418_115452-1zt0rgyx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/idao-2021-finals/wandb/run-20210418_115452-1zt0rgyx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>validation_f1</td><td>0.66126</td></tr><tr><td>anic</td><td>5699.0805</td></tr><tr><td>public_anic</td><td>5800.68067</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">2021-04-18_11:54:51</strong>: <a href=\"https://wandb.ai/artkulak/idao-2021-finals/runs/1zt0rgyx\" target=\"_blank\">https://wandb.ai/artkulak/idao-2021-finals/runs/1zt0rgyx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if USE_WANDB:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
