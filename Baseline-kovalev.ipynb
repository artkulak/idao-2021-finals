{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36a4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# IMPORT LIBS\n",
    "#####################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scoring import local_scorer\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "#####################\n",
    "# SET CONSTANTS\n",
    "#####################\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "OUTPUT_PATH = Path('../output')\n",
    "TRAIN_PATH = INPUT_PATH \n",
    "\n",
    "TARGET_COLUMNS = ['sale_flg', 'sale_amount', 'contacts']\n",
    "FIXED_SEEDS = [948, 534, 432, 597, 103, 21, 2242, 17, 20, 29]\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "USE_WANDB = False\n",
    "CURRENT_TIME = str(datetime.datetime.now()).replace(' ', '_').split('.')[0]\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb6e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Config\n",
    "###############\n",
    "\n",
    "n_seed = 3\n",
    "n_fold = 3\n",
    "prediction_threshold = 0.2\n",
    "retrain_after_valid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53be64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=\"idao-2021-finals\", name = f'{CURRENT_TIME}') # todo add config here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8c5f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/decorator.py:231: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return caller(func, *(extras + args), **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.94 s, sys: 2.27 s, total: 9.21 s\n",
      "Wall time: 9.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transactions = pd.read_csv(INPUT_PATH / 'trxn.csv')\n",
    "assets_under_management = pd.read_csv(INPUT_PATH / 'aum.csv')\n",
    "balance = pd.read_csv(INPUT_PATH / 'balance.csv')\n",
    "client = pd.read_csv(INPUT_PATH / 'client.csv')\n",
    "campaigns = pd.read_csv(INPUT_PATH / 'com.csv')\n",
    "deals = pd.read_csv(INPUT_PATH / 'deals.csv')\n",
    "dict_merchant_category_code = pd.read_csv(INPUT_PATH / 'dict_mcc.csv')\n",
    "payments = pd.read_csv(INPUT_PATH / 'payments.csv')\n",
    "funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "appl = pd.read_csv(INPUT_PATH / 'appl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f27d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = payments.sort_values(by='day_dt', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8eaadf",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "90c45c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>agrmnt_start_dt</th>\n",
       "      <th>agrmnt_close_dt</th>\n",
       "      <th>crncy_cd</th>\n",
       "      <th>agrmnt_rate_active</th>\n",
       "      <th>agrmnt_rate_passive</th>\n",
       "      <th>agrmnt_sum_rur</th>\n",
       "      <th>prod_type_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7513301859607023584</td>\n",
       "      <td>2010-08-12</td>\n",
       "      <td>2014-10-30</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash on demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7513301859607023584</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013-08-16</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash on demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513301859607023584</td>\n",
       "      <td>2013-08-16</td>\n",
       "      <td>2014-02-14</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash on demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7513301859607023584</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash on demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7513301859607023584</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash on demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109011</th>\n",
       "      <td>-8242641659611256965</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POST OFFICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109012</th>\n",
       "      <td>-8242641659611256965</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.25</td>\n",
       "      <td>13089.0</td>\n",
       "      <td>POST OFFICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109013</th>\n",
       "      <td>-8242641659611256965</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POST OFFICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109014</th>\n",
       "      <td>-8242641659611256965</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>2012-09-18</td>\n",
       "      <td>810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5403.0</td>\n",
       "      <td>POST OFFICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109015</th>\n",
       "      <td>-4636514022054340174</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>810.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3299986.0</td>\n",
       "      <td>Mortgage plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109016 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  client_id agrmnt_start_dt agrmnt_close_dt  crncy_cd  \\\n",
       "0       7513301859607023584      2010-08-12      2014-10-30     810.0   \n",
       "1       7513301859607023584      2013-02-15      2013-08-16     810.0   \n",
       "2       7513301859607023584      2013-08-16      2014-02-14     810.0   \n",
       "3       7513301859607023584      2015-07-12      2015-07-12     810.0   \n",
       "4       7513301859607023584      2015-07-12      2015-07-12     810.0   \n",
       "...                     ...             ...             ...       ...   \n",
       "109011 -8242641659611256965      2011-08-10      2011-08-10     810.0   \n",
       "109012 -8242641659611256965      2011-08-10      2018-07-03     810.0   \n",
       "109013 -8242641659611256965      2011-08-10      2011-08-10     810.0   \n",
       "109014 -8242641659611256965      2011-08-23      2012-09-18     810.0   \n",
       "109015 -4636514022054340174      2014-06-09      2017-07-31     810.0   \n",
       "\n",
       "        agrmnt_rate_active  agrmnt_rate_passive  agrmnt_sum_rur  \\\n",
       "0                      NaN                  NaN             0.0   \n",
       "1                      NaN                  NaN             0.0   \n",
       "2                      NaN                  NaN             0.0   \n",
       "3                      NaN                  NaN             0.0   \n",
       "4                      NaN                  NaN             0.0   \n",
       "...                    ...                  ...             ...   \n",
       "109011                 NaN                  NaN             0.0   \n",
       "109012                 NaN                 3.25         13089.0   \n",
       "109013                 NaN                  NaN             0.0   \n",
       "109014                 NaN                 7.00          5403.0   \n",
       "109015               18.75                  NaN       3299986.0   \n",
       "\n",
       "        prod_type_name  \n",
       "0       Cash on demand  \n",
       "1       Cash on demand  \n",
       "2       Cash on demand  \n",
       "3       Cash on demand  \n",
       "4       Cash on demand  \n",
       "...                ...  \n",
       "109011     POST OFFICE  \n",
       "109012     POST OFFICE  \n",
       "109013     POST OFFICE  \n",
       "109014     POST OFFICE  \n",
       "109015   Mortgage plus  \n",
       "\n",
       "[109016 rows x 8 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "88441d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id\n",
       "-9221941791080978530    0.000000e+00\n",
       "-9220369594510368140    6.634224e+07\n",
       "-9220236243053692422    0.000000e+00\n",
       "-9220233431709087652    9.242713e+04\n",
       "-9219699286371310531    0.000000e+00\n",
       "                            ...     \n",
       " 9218801691173598782    2.723500e+03\n",
       " 9219024469308275500    0.000000e+00\n",
       " 9219968212912398941    0.000000e+00\n",
       " 9220335314469087849    9.004667e+03\n",
       " 9223107459698100059    0.000000e+00\n",
       "Name: agrmnt_sum_rur, Length: 18652, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deals.groupby('client_id')['agrmnt_sum_rur'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['mcc_cd'] = transactions['mcc_cd'].fillna(-2)\n",
    "transactions['txn_city'] = transactions['txn_city'].fillna('<UNK>')\n",
    "transactions['tsp_name'] = transactions['tsp_name'].fillna('<UNK>')\n",
    "transactions['txn_comment_2'] = transactions['txn_comment_2'].fillna('<UNK>')\n",
    "transactions.merge(dict_merchant_category_code, on='mcc_cd', how='left')\n",
    "transactions['brs_mcc_group'] = transactions['brs_mcc_group'].fillna('<UNK>')\n",
    "transactions['brs_mcc_subgroup'] = transactions['brs_mcc_subgroup'].fillna('<UNK>')\n",
    "\n",
    "balance['crncy_cd'] = balance['crncy_cd'].fillna(-2)\n",
    "balance['prod_cat_name'] = balance['prod_cat_name'].fillna('<UNK>')\n",
    "balance['prod_group_name'] = balance['prod_group_name'].fillna('<UNK>')\n",
    "\n",
    "client = client.rename(columns={\n",
    "    'gender': 'client_gender',\n",
    "    'age': 'client_age',\n",
    "    'region': 'client_region',\n",
    "    'city': 'client_city',\n",
    "    'citizenship': 'client_citizenship',\n",
    "    'education': 'client_education',\n",
    "    'job_type': 'client_job_type'\n",
    "})\n",
    "\n",
    "campaigns['prod'] = campaigns['prod'].fillna('<UNK>')\n",
    "\n",
    "deals['crncy_cd'] = deals['crncy_cd'].fillna(-2)\n",
    "deals['agrmnt_rate_active'] = deals['agrmnt_rate_active'].fillna(-2)\n",
    "deals['agrmnt_rate_passive'] = deals['agrmnt_rate_passive'].fillna(-2)\n",
    "deals['agrmnt_sum_rur'] = deals['agrmnt_sum_rur'].fillna(-2)\n",
    "deals['prod_type_name'] = deals['prod_type_name'].fillna('<UNK>')\n",
    "deals['argmnt_close_start_days'] = (pd.to_datetime(deals['agrmnt_close_dt']) - pd.to_datetime(deals['agrmnt_start_dt'])).dt.days.fillna(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf0f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(x, default='unknown'):\n",
    "    try:\n",
    "        # works faster then value_counts and pd.Series.mode\n",
    "        return scipy.stats.mode(x)[0][0]\n",
    "    except: \n",
    "        return default\n",
    "\n",
    "\n",
    "def get_feature_total(df, col_name):\n",
    "    return data['client_id'].map(df.groupby(['client_id', col_name]).size().index.get_level_values('client_id').value_counts()).fillna(0)\n",
    "\n",
    "\n",
    "def get_feature_most_common(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: scipy.stats.mode(x)[0][0])).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_max(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].max()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_min(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].min()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_mean(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].mean()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_std(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].std()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_max_min(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: x.max() - x.min())).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def create_features_transactions(data):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    # transaction features\n",
    "    data['total_transactions'] = data['client_id'].map(transactions.groupby('client_id').size()).fillna(0)\n",
    "    data['total_cards'] = get_feature_total(transactions, 'card_id')\n",
    "\n",
    "#     data['total_transaction_amount'] = data['client_id'].map(transactions.groupby('client_id')['tran_amt_rur'].sum()).fillna(0) # add monthly, daily, etc\n",
    "    data['mean_transaction_amt'] = get_feature_mean(transactions, 'tran_amt_rur', -1) # add monthly, daily, etc\n",
    "    data['std_transaction_amount'] = get_feature_std(transactions, 'tran_amt_rur', -1) # add monthly, daily, etc\n",
    "    \n",
    "    data['total_mcc_cd'] = get_feature_total(transactions, 'mcc_cd')\n",
    "    data['total_share_mcc_cd'] = (data['total_mcc_cd'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_mcc_cd'] = get_feature_most_common(transactions, 'mcc_cd', -1)\n",
    "    \n",
    "    data['total_merchant_cd'] = get_feature_total(transactions, 'merchant_cd')\n",
    "    data['total_share_merchant_cd'] = (data['total_merchant_cd'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_merchant_cd'] = get_feature_most_common(transactions, 'merchant_cd', -1)\n",
    "    \n",
    "    data['total_txn_city'] = get_feature_total(transactions, 'txn_city')\n",
    "    data['total_share_txn_city'] = (data['total_txn_city'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_txn_city'] = get_feature_most_common(transactions, 'txn_city', '<unknown>')\n",
    "    \n",
    "    data['total_tsp_name'] = get_feature_total(transactions, 'tsp_name')\n",
    "    data['total_share_tsp_name'] = (data['total_tsp_name'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_tsp_name'] = get_feature_most_common(transactions, 'tsp_name', '<unknown>')\n",
    "    \n",
    "    data['total_txn_comment_1'] = get_feature_total(transactions, 'txn_comment_1')\n",
    "    data['most_common_txn_comment_1'] = get_feature_most_common(transactions, 'txn_comment_1', '<unknown>')\n",
    "    \n",
    "    data['total_txn_comment_2'] = get_feature_total(transactions, 'txn_comment_2')\n",
    "    data['most_common_txn_comment_2'] = get_feature_most_common(transactions, 'txn_comment_2', '<unknown>')\n",
    "    \n",
    "    data['total_brs_mcc_group'] = get_feature_total(transactions, 'brs_mcc_group')\n",
    "    data['most_common_brs_mcc_group'] = get_feature_most_common(transactions, 'brs_mcc_group', '<unknown>')\n",
    "    \n",
    "    data['total_brs_mcc_subgroup'] = get_feature_total(transactions, 'brs_mcc_subgroup')\n",
    "    data['most_common_brs_mcc_subgroup'] = get_feature_most_common(transactions, 'brs_mcc_subgroup', '<unknown>')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_aum(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data['total_aum'] = data['client_id'].map(assets_under_management.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "    data['total_product_code'] = get_feature_total(assets_under_management, 'product_code')\n",
    "    data['most_common_product_code'] = get_feature_most_common(assets_under_management, 'product_code', '<unknown>').value_counts()\n",
    "    \n",
    "    data['mean_balance_rur_amt'] = get_feature_mean(assets_under_management, 'balance_rur_amt', -1)\n",
    "    data['std_balance_rur_amt'] = get_feature_std(assets_under_management, 'balance_rur_amt', -1)\n",
    "    data['max_min_balance_rur_amt'] = get_feature_max_min(assets_under_management, 'balance_rur_amt', -1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_balance(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data['total_balance'] = data['client_id'].map(balance.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "    data['total_balance_crncy_cd'] = get_feature_total(balance, 'crncy_cd')\n",
    "    data['most_common_balance_crncy_cd'] = get_feature_most_common(balance, 'crncy_cd', -1)\n",
    "    \n",
    "    data['total_eop_bal_sum_rur'] = get_feature_total(balance, 'eop_bal_sum_rur')\n",
    "    data['total_share_eop_bal_sum_rur'] = (data['total_eop_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_eop_bal_sum_rur'] = get_feature_mean(balance, 'eop_bal_sum_rur', -9999)\n",
    "    data['std_eop_bal_sum_rur'] = get_feature_std(balance, 'eop_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_min_bal_sum_rur'] = get_feature_total(balance, 'min_bal_sum_rur')\n",
    "    data['total_share_min_bal_sum_rur'] = (data['total_min_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_min_bal_sum_rur'] = get_feature_mean(balance, 'min_bal_sum_rur', -9999)\n",
    "    data['std_min_bal_sum_rur'] = get_feature_std(balance, 'min_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_max_bal_sum_rur'] = get_feature_total(balance, 'max_bal_sum_rur')\n",
    "    data['total_share_max_bal_sum_rur'] = (data['total_max_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_max_bal_sum_rur'] = get_feature_mean(balance, 'max_bal_sum_rur', -9999)\n",
    "    data['std_max_bal_sum_rur'] = get_feature_std(balance, 'max_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_avg_bal_sum_rur'] = get_feature_total(balance, 'avg_bal_sum_rur')\n",
    "    data['total_share_avg_bal_sum_rur'] = (data['total_avg_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_avg_bal_sum_rur'] = get_feature_mean(balance, 'avg_bal_sum_rur', -9999)\n",
    "    data['std_avg_bal_sum_rur'] = get_feature_std(balance, 'avg_bal_sum_rur', -9999)\n",
    "    data['max_min_avg_bal_sum_rur'] = get_feature_max_min(balance, 'avg_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_prod_cat_name'] = get_feature_total(balance, 'prod_cat_name')\n",
    "    data['most_common_prod_cat_name'] = get_feature_most_common(balance, 'prod_cat_name', '<unknown>')\n",
    "    \n",
    "    data['total_prod_group_name'] = get_feature_total(balance, 'prod_group_name')\n",
    "    data['most_common_prod_group_name'] = get_feature_most_common(balance, 'prod_group_name', '<unknown>')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_client(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data = data.merge(client, on='client_id')\n",
    "    data['match_client_region-region_cd'] = (data['client_region'] == data['region_cd']).astype(int)\n",
    "    data.drop('client_citizenship', axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_campaigns(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data['total_campaigns'] = data['client_id'].map(campaigns.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "    data['total_agr_flg'] = get_feature_total(campaigns, 'agr_flg')\n",
    "    data['mean_agr_flg'] = get_feature_mean(campaigns, 'agr_flg', -1)\n",
    "    \n",
    "    data['total_otkaz'] = get_feature_total(campaigns, 'otkaz')\n",
    "    data['mean_otkaz'] = get_feature_mean(campaigns, 'otkaz', -1)\n",
    "    \n",
    "    data['total_dumaet'] = get_feature_total(campaigns, 'dumaet')\n",
    "    data['mean_dumaet'] = get_feature_mean(campaigns, 'dumaet', -1)\n",
    "    \n",
    "    data['total_ring_up_flg'] = get_feature_total(campaigns, 'ring_up_flg')\n",
    "    data['most_common_ring_up_flg'] = get_feature_most_common(campaigns, 'ring_up_flg', -1)\n",
    "    \n",
    "    data['total_count_comm'] = get_feature_total(campaigns, 'count_comm')\n",
    "    data['most_common_count_comm'] = get_feature_most_common(campaigns, 'count_comm', -1)\n",
    "    \n",
    "    data['total_channel'] = get_feature_total(campaigns, 'channel')\n",
    "    data['most_common_channel'] = get_feature_most_common(campaigns, 'channel', '<unknown>')\n",
    "    \n",
    "    data['total_prod'] = get_feature_total(campaigns, 'prod')\n",
    "    data['most_common_prod'] = get_feature_most_common(campaigns, 'prod', '<unknown>')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_deals(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data['total_deals'] = data['client_id'].map(deals.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "    data['total_deals_crncy_cd'] = get_feature_total(deals, 'crncy_cd')\n",
    "    data['most_common_deals_crncy_cd'] = get_feature_most_common(deals, 'crncy_cd', -1)\n",
    "    \n",
    "    data['total_agrmnt_rate_active'] = get_feature_total(deals, 'agrmnt_rate_active')\n",
    "    data['max_agrmnt_rate_active'] = get_feature_max(deals, 'agrmnt_rate_active', -1)\n",
    "    \n",
    "    data['total_agrmnt_rate_passive'] = get_feature_total(deals, 'agrmnt_rate_passive')\n",
    "    data['max_agrmnt_rate_passive'] = get_feature_max(deals, 'agrmnt_rate_passive', -1)\n",
    "    \n",
    "    data['total_agrmnt_sum_rur'] = get_feature_total(deals, 'agrmnt_sum_rur')\n",
    "    data['mean_agrmnt_sum_rur'] = get_feature_mean(deals, 'agrmnt_sum_rur', -1)\n",
    "    data['std_agrmnt_sum_rur'] = get_feature_std(deals, 'agrmnt_sum_rur', -1)\n",
    "    \n",
    "    data['total_prod_type_name'] = get_feature_total(deals, 'prod_type_name')\n",
    "    data['most_common_prod_type_name'] = get_feature_most_common(deals, 'prod_type_name', '<unknown>')\n",
    "    \n",
    "    data['total_argmnt_close_start_days'] = get_feature_total(deals, 'argmnt_close_start_days')\n",
    "    data['max_argmnt_close_start_days'] = get_feature_max(deals, 'argmnt_close_start_days', -1)\n",
    "    data['min_argmnt_close_start_days'] = get_feature_min(deals, 'argmnt_close_start_days', -1)\n",
    "    data['mean_argmnt_close_start_days'] = get_feature_mean(deals, 'argmnt_close_start_days', -1)\n",
    "    data['std_argmnt_close_start_days'] = get_feature_std(deals, 'argmnt_close_start_days', -1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_dict_mcc(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_payments(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    # payments \n",
    "    data['last_known_salary'] = data['client_id'].map(payments.groupby('client_id').apply(lambda x: x['sum_rur'].iloc[0])).fillna(-1)\n",
    "    data['total_recieved_salary'] = data['client_id'].map(payments.groupby('client_id').apply(lambda x: x['sum_rur'].sum())).fillna(-1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_appl(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_funnel(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "99fa50d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 196 ms, total: 38.2 s\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create features\n",
    "\n",
    "data = create_features_transactions(data)\n",
    "data = create_features_aum(data)\n",
    "data = create_features_balance(data)\n",
    "data = create_features_client(data)\n",
    "data = create_features_campaigns(data)\n",
    "data = create_features_deals(data)\n",
    "data = create_features_dict_mcc(data)\n",
    "data = create_features_payments(data)\n",
    "data = create_features_appl(data)\n",
    "data = create_features_funnel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "721825e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_features_deals(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e246514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data encode\n",
    "\n",
    "le = LabelEncoder()\n",
    "fill_cols = ['gender', 'citizenship', 'education', 'job_type', 'most_common_txn_comment_1', 'most_common_txn_city', 'most_common_txn_country']\n",
    "for col in fill_cols:\n",
    "    data[col] = le.fit_transform(data[col].astype(str))\n",
    "    joblib.dump(le, OUTPUT_PATH / 'preprocessors' / f'{col}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d6345ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = TARGET_COLUMNS + ['client_id'])\n",
    "Y = data[TARGET_COLUMNS[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5ef27",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "42da0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    os.mkdir(OUTPUT_PATH / 'models')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'models')\n",
    "    os.mkdir(OUTPUT_PATH / 'models')\n",
    "    \n",
    "try:\n",
    "    os.mkdir(OUTPUT_PATH / 'preprocessors')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'preprocessors')\n",
    "    os.mkdir(OUTPUT_PATH / 'preprocessors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8a30587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_train(X_train, Y_train, X_val, Y_val, i_fold=None, seed=None, params = None):\n",
    "    # prepare for train\n",
    "    \n",
    "    params = {\n",
    "              \"n_jobs\":-1,\n",
    "              \"random_state\": seed\n",
    "              }\n",
    "    \n",
    "    \n",
    "    model = LGBMClassifier(**params) # define model here\n",
    "    \n",
    "    # Fit and save model\n",
    "    \n",
    "    if X_val is None:\n",
    "        model.fit(X_train, Y_train, verbose=False)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train,   eval_set=(X_val, Y_val), early_stopping_rounds=500, verbose=False)\n",
    "    joblib.dump(model, OUTPUT_PATH / 'models' / f'lightgbm_{i_fold}_{seed}_{CURRENT_TIME}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f2f0c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 948, 1/3\n",
      "# Fold: 1/3 (seed: 1/3)\n",
      "predict on oof...  done.\n",
      "# Fold: 2/3 (seed: 1/3)\n",
      "predict on oof...  done.\n",
      "# Fold: 3/3 (seed: 1/3)\n",
      "predict on oof...  done.\n",
      "Seed: 534, 2/3\n",
      "# Fold: 1/3 (seed: 2/3)\n",
      "predict on oof...  done.\n",
      "# Fold: 2/3 (seed: 2/3)\n",
      "predict on oof...  done.\n",
      "# Fold: 3/3 (seed: 2/3)\n",
      "predict on oof...  done.\n",
      "Seed: 432, 3/3\n",
      "# Fold: 1/3 (seed: 3/3)\n",
      "predict on oof...  done.\n",
      "# Fold: 2/3 (seed: 3/3)\n",
      "predict on oof...  done.\n",
      "# Fold: 3/3 (seed: 3/3)\n",
      "predict on oof...  done.\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros((X.shape[0], n_seed)) # cv_score\n",
    "seeds = []\n",
    "for i_seed in range(n_seed):\n",
    "    seed = FIXED_SEEDS[i_seed]\n",
    "    seed_everything(seed)\n",
    "\n",
    "    seeds.append(seed)\n",
    "    print('Seed: {}, {}/{}'.format(seed, i_seed + 1, n_seed))\n",
    "    \n",
    "    if n_fold != 1:\n",
    "        kf = KFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "        split_indexes = kf.split(X, Y)\n",
    "    else:\n",
    "        split_indexes = [train_test_split(np.arange(X.shape[0]), random_state=seed, shuffle = True)]\n",
    "    \n",
    "    for i_fold, (train_idx, val_idx) in enumerate(split_indexes):\n",
    "        print(\"# Fold: {}/{} (seed: {}/{})\".format(i_fold + 1, n_fold, i_seed + 1, n_seed))\n",
    "\n",
    "        # dataset\n",
    "        X_train, Y_train = X.iloc[train_idx], Y[train_idx]\n",
    "        X_val, Y_val = X.iloc[val_idx], Y[val_idx]\n",
    "\n",
    "\n",
    "        # train\n",
    "        running_train(X_train, Y_train, X_val, Y_val, i_fold=i_fold, seed=seed)\n",
    "\n",
    "        # predict on oof\n",
    "        print('predict on oof...', end='')\n",
    "        model = joblib.load( OUTPUT_PATH / 'models' / f'lightgbm_{i_fold}_{seed}_{CURRENT_TIME}.pkl')\n",
    "\n",
    "        prediction = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        oof[val_idx, i_seed] = prediction\n",
    "        print('  done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "98e180a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_fold != 1:\n",
    "    Y_predicted = (np.mean(oof, axis = 1) > prediction_threshold).astype(int)\n",
    "    Y_test = funnel[['client_id', 'sale_flg']].set_index('client_id')\n",
    "    test_funnel =  funnel.set_index('client_id')\n",
    "if n_fold == 1 and n_seed == 1:\n",
    "    Y_predicted = (prediction > prediction_threshold).astype(int)\n",
    "    Y_test = funnel[['client_id', 'sale_flg']].iloc[split_indexes[0][1]].set_index('client_id')\n",
    "    test_funnel = funnel.iloc[split_indexes[0][1]].set_index('client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e7467202",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir(OUTPUT_PATH / 'scoring')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'scoring')\n",
    "    os.mkdir(OUTPUT_PATH / 'scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5ecf52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/home/jupyter/idao-2021-finals/scoring/scorer.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected['gain'] = selected[SALE_FLAG] * selected[SALE_AMOUNT].fillna(0) - selected[CONTACTS] * CALL_COST\n"
     ]
    }
   ],
   "source": [
    "public_score, private_score = local_scorer.get_score(test_funnel, Y_predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "26fca666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public ANIC 5365.358979905113 Private ANIC 5653.409841613172\n",
      "ANIC 5557.392887710485\n",
      "Accuracy score: 0.8324495301888548\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = accuracy_score(Y_test['sale_flg'], Y_predicted)\n",
    "print(f'Public ANIC {public_score} Private ANIC {private_score}')\n",
    "print(f'ANIC {1/3*public_score+ 2/3 * private_score}')\n",
    "print(f'Accuracy score: {validation_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "55fbb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.run.summary[\"validation_accuracy\"] = validation_accuracy\n",
    "    wandb.run.summary[\"anic\"] = (public_score + private_score) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf63865",
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_after_valid:\n",
    "    running_train(X, Y, None, None, i_fold=-1, seed=4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bce2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
