{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89f21ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# IMPORT LIBS\n",
    "#####################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scoring import local_scorer\n",
    "import scipy\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#####################\n",
    "# SET CONSTANTS\n",
    "#####################\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "OUTPUT_PATH = Path('../output')\n",
    "TRAIN_PATH = INPUT_PATH \n",
    "\n",
    "TARGET_COLUMNS = ['sale_flg', 'sale_amount', 'contacts']\n",
    "FIXED_SEEDS = [948, 534, 432, 597, 103, 21, 2242, 17, 20, 29]\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "USE_WANDB = False\n",
    "CURRENT_TIME = str(datetime.datetime.now()).replace(' ', '_').split('.')[0]\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3e1da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Config\n",
    "###############\n",
    "\n",
    "n_seed = 5\n",
    "n_fold = 3\n",
    "retrain_after_valid = True\n",
    "make_submission = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2dc3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=\"idao-2021-finals\", name = f'{CURRENT_TIME}') # todo add config here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fccea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "\n",
    "# transactions = pd.read_csv(INPUT_PATH / 'trxn.csv')\n",
    "# assets_under_management = pd.read_csv(INPUT_PATH / 'aum.csv')\n",
    "# balance = pd.read_csv(INPUT_PATH / 'balance.csv')\n",
    "# client = pd.read_csv(INPUT_PATH / 'client.csv')\n",
    "# campaigns = pd.read_csv(INPUT_PATH / 'com.csv')\n",
    "# deals = pd.read_csv(INPUT_PATH / 'deals.csv')\n",
    "# dict_merchant_category_code = pd.read_csv(INPUT_PATH / 'dict_mcc.csv')\n",
    "# payments = pd.read_csv(INPUT_PATH / 'payments.csv')\n",
    "# funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "# appl = pd.read_csv(INPUT_PATH / 'appl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570b3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_total(df, col_name):\n",
    "    return data['client_id'].map(df.groupby(['client_id', col_name]).size().index.get_level_values('client_id').value_counts()).fillna(0)\n",
    "\n",
    "\n",
    "def get_feature_most_common(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: scipy.stats.mode(x)[0][0])).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_max(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].max()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_min(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].min()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_mean(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].mean()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_std(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].std()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_max_min(df, col_name, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: x.max() - x.min())).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_timedelta(df, col_name):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name].agg(lambda x: (x.max() - x.min()).days)).fillna(-1)\n",
    "\n",
    "\n",
    "def get_feature_diff(df, col_name1, col_name2, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name1].sum() - df.groupby('client_id')[col_name2].sum()).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def get_feature_rate(df, col_name1, col_name2, fill_na_value):\n",
    "    return data['client_id'].map(df.groupby('client_id')[col_name1].sum() / (df.groupby('client_id')[col_name2].sum() + 1e-12)).fillna(fill_na_value)\n",
    "\n",
    "\n",
    "def create_features_transactions(data):\n",
    "    \n",
    "    transactions = pd.read_csv(INPUT_PATH / 'trxn.csv')\n",
    "    dict_merchant_category_code = pd.read_csv(INPUT_PATH / 'dict_mcc.csv')\n",
    "    \n",
    "    transactions['mcc_cd'] = transactions['mcc_cd'].fillna(-2)\n",
    "    transactions['txn_city'] = transactions['txn_city'].fillna('<UNK>')\n",
    "    transactions['tsp_name'] = transactions['tsp_name'].fillna('<UNK>')\n",
    "    transactions['txn_comment_2'] = transactions['txn_comment_2'].fillna('<UNK>')\n",
    "\n",
    "    transactions = transactions.merge(dict_merchant_category_code, on='mcc_cd', how='left')\n",
    "    del dict_merchant_category_code\n",
    "    transactions['brs_mcc_group'] = transactions['brs_mcc_group'].fillna('<UNK>')\n",
    "    transactions['brs_mcc_subgroup'] = transactions['brs_mcc_subgroup'].fillna('<UNK>')\n",
    "    \n",
    "    data['total_transactions'] = data['client_id'].map(transactions.groupby('client_id').size()).fillna(0)\n",
    "#     data['total_transactions_cards'] = get_feature_total(transactions, 'card_id')\n",
    "\n",
    "#     data['total_transaction_amount'] = data['client_id'].map(transactions.groupby('client_id')['tran_amt_rur'].sum()).fillna(0) # add monthly, daily, etc\n",
    "    data['mean_transaction_amt'] = get_feature_mean(transactions, 'tran_amt_rur', -1) # add monthly, daily, etc\n",
    "    data['std_transaction_amount'] = get_feature_std(transactions, 'tran_amt_rur', -1) # add monthly, daily, etc\n",
    "    \n",
    "    data['total_transactions_mcc_cd'] = get_feature_total(transactions, 'mcc_cd')\n",
    "    data['total_transactions_share_mcc_cd'] = (data['total_transactions_mcc_cd'] / data['total_transactions']).fillna(0)\n",
    "#     data['most_common_transactions_mcc_cd'] = get_feature_most_common(transactions, 'mcc_cd', -1)\n",
    "    \n",
    "    data['total_transactions_merchant_cd'] = get_feature_total(transactions, 'merchant_cd')\n",
    "    data['total_share_transactions_merchant_cd'] = (data['total_transactions_merchant_cd'] / data['total_transactions']).fillna(0)\n",
    "#     data['most_common_transactions_merchant_cd'] = get_feature_most_common(transactions, 'merchant_cd', -1)\n",
    "    \n",
    "    data['total_transactions_txn_city'] = get_feature_total(transactions, 'txn_city')\n",
    "    data['total_share_transactions_txn_city'] = (data['total_transactions_txn_city'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_transactions_txn_city'] = get_feature_most_common(transactions, 'txn_city', '<unknown>')\n",
    "    \n",
    "    data['total_transactions_tsp_name'] = get_feature_total(transactions, 'tsp_name')\n",
    "    data['total_share_transactions_tsp_name'] = (data['total_transactions_tsp_name'] / data['total_transactions']).fillna(0)\n",
    "    data['most_common_transactions_tsp_name'] = get_feature_most_common(transactions, 'tsp_name', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_txn_comment_1'] = get_feature_total(transactions, 'txn_comment_1')\n",
    "#     data['most_common_transactions_txn_comment_1'] = get_feature_most_common(transactions, 'txn_comment_1', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_txn_comment_2'] = get_feature_total(transactions, 'txn_comment_2')\n",
    "#     data['most_common_transactions_txn_comment_2'] = get_feature_most_common(transactions, 'txn_comment_2', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_brs_mcc_group'] = get_feature_total(transactions, 'brs_mcc_group')\n",
    "#     data['most_common_transactions_brs_mcc_group'] = get_feature_most_common(transactions, 'brs_mcc_group', '<unknown>')\n",
    "    \n",
    "#     data['total_transactions_brs_mcc_subgroup'] = get_feature_total(transactions, 'brs_mcc_subgroup')\n",
    "#     data['most_common_transactions_brs_mcc_subgroup'] = get_feature_most_common(transactions, 'brs_mcc_subgroup', '<unknown>')\n",
    "    \n",
    "    del transactions\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_aum(data):\n",
    "    \n",
    "    assets_under_management = pd.read_csv(INPUT_PATH / 'aum.csv')\n",
    "    \n",
    "    data['total_aum'] = data['client_id'].map(assets_under_management.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_aum_product_code'] = get_feature_total(assets_under_management, 'product_code')\n",
    "#     data['most_common_aum_product_code'] = get_feature_most_common(assets_under_management, 'product_code', '<unknown>').value_counts()\n",
    "    \n",
    "    data['mean_aum_balance_rur_amt'] = get_feature_mean(assets_under_management, 'balance_rur_amt', -1)\n",
    "    data['std_aum_balance_rur_amt'] = get_feature_std(assets_under_management, 'balance_rur_amt', -1)\n",
    "    data['max_min_aum_balance_rur_amt'] = get_feature_max_min(assets_under_management, 'balance_rur_amt', -1)\n",
    "    \n",
    "    del assets_under_management\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_balance(data):\n",
    "    \n",
    "    balance = pd.read_csv(INPUT_PATH / 'balance.csv')\n",
    "    \n",
    "    balance['crncy_cd'] = balance['crncy_cd'].fillna(-2)\n",
    "    balance['prod_cat_name'] = balance['prod_cat_name'].fillna('<UNK>')\n",
    "    balance['prod_group_name'] = balance['prod_group_name'].fillna('<UNK>')\n",
    "    \n",
    "    data['total_balance'] = data['client_id'].map(balance.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_balance_crncy_cd'] = get_feature_total(balance, 'crncy_cd')\n",
    "#     data['most_common_balance_crncy_cd'] = get_feature_most_common(balance, 'crncy_cd', -1)\n",
    "    \n",
    "#     data['total_balance_eop_bal_sum_rur'] = get_feature_total(balance, 'eop_bal_sum_rur')\n",
    "    data['total_share_balance_eop_bal_sum_rur'] = (get_feature_total(balance, 'eop_bal_sum_rur') / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_eop_bal_sum_rur'] = get_feature_mean(balance, 'eop_bal_sum_rur', -9999)\n",
    "    data['std_balance_eop_bal_sum_rur'] = get_feature_std(balance, 'eop_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_balance_min_bal_sum_rur'] = get_feature_total(balance, 'min_bal_sum_rur')\n",
    "    data['total_share_balance_min_bal_sum_rur'] = (data['total_balance_min_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_min_bal_sum_rur'] = get_feature_mean(balance, 'min_bal_sum_rur', -9999)\n",
    "    data['std_balance_min_bal_sum_rur'] = get_feature_std(balance, 'min_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_balance_max_bal_sum_rur'] = get_feature_total(balance, 'max_bal_sum_rur')\n",
    "    data['total_share_balance_max_bal_sum_rur'] = (data['total_balance_max_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_max_bal_sum_rur'] = get_feature_mean(balance, 'max_bal_sum_rur', -9999)\n",
    "    data['std_balance_max_bal_sum_rur'] = get_feature_std(balance, 'max_bal_sum_rur', -9999)\n",
    "    \n",
    "    data['total_balance_avg_bal_sum_rur'] = get_feature_total(balance, 'avg_bal_sum_rur')\n",
    "    data['total_share_balance_avg_bal_sum_rur'] = (data['total_balance_avg_bal_sum_rur'] / data['total_balance']).fillna(0)\n",
    "    data['mean_balance_avg_bal_sum_rur'] = get_feature_mean(balance, 'avg_bal_sum_rur', -9999)\n",
    "#     data['std_balance_avg_bal_sum_rur'] = get_feature_std(balance, 'avg_bal_sum_rur', -9999)\n",
    "    data['max_min_balance_avg_bal_sum_rur'] = get_feature_max_min(balance, 'avg_bal_sum_rur', -9999)\n",
    "    \n",
    "#     data['total_balance_prod_cat_name'] = get_feature_total(balance, 'prod_cat_name')\n",
    "#     data['most_common_balance_prod_cat_name'] = get_feature_most_common(balance, 'prod_cat_name', '<unknown>')\n",
    "    \n",
    "    data['total_balance_prod_group_name'] = get_feature_total(balance, 'prod_group_name')\n",
    "#     data['most_common_balance_prod_group_name'] = get_feature_most_common(balance, 'prod_group_name', '<unknown>')\n",
    "    \n",
    "    del balance\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_client(data):\n",
    "    \n",
    "    client = pd.read_csv(INPUT_PATH / 'client.csv')\n",
    "    \n",
    "    client = client.rename(columns={\n",
    "        'gender': 'client_gender',\n",
    "        'age': 'client_age',\n",
    "        'region': 'client_region',\n",
    "        'city': 'client_city',\n",
    "        'citizenship': 'client_citizenship',\n",
    "        'education': 'client_education',\n",
    "        'job_type': 'client_job_type'\n",
    "    })\n",
    "    \n",
    "    data = data.merge(client, on='client_id')\n",
    "#     data['match_client_region-region_cd'] = (data['client_region'] == data['region_cd']).astype(int)\n",
    "    data = data.drop(['client_citizenship', 'client_job_type', 'client_gender'], axis=1)\n",
    "    \n",
    "    del client\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_campaigns(data):\n",
    "\n",
    "    campaigns = pd.read_csv(INPUT_PATH / 'com.csv')\n",
    "    \n",
    "    campaigns['prod'] = campaigns['prod'].fillna('<UNK>')\n",
    "    \n",
    "    data['total_campaigns'] = data['client_id'].map(campaigns.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_campaigns_agr_flg'] = get_feature_total(campaigns, 'agr_flg')\n",
    "    data['mean_campaigns_agr_flg'] = get_feature_mean(campaigns, 'agr_flg', -1)\n",
    "    \n",
    "#     data['total_campaigns_otkaz'] = get_feature_total(campaigns, 'otkaz')\n",
    "    data['mean_campaigns_otkaz'] = get_feature_mean(campaigns, 'otkaz', -1)\n",
    "    \n",
    "#     data['total_campaigns_dumaet'] = get_feature_total(campaigns, 'dumaet')\n",
    "    data['mean_campaigns_dumaet'] = get_feature_mean(campaigns, 'dumaet', -1)\n",
    "    \n",
    "#     data['total_campaigns_ring_up_flg'] = get_feature_total(campaigns, 'ring_up_flg')\n",
    "#     data['most_common_campaigns_ring_up_flg'] = get_feature_most_common(campaigns, 'ring_up_flg', -1)\n",
    "    \n",
    "#     data['total_campaigns_count_comm'] = get_feature_total(campaigns, 'count_comm')\n",
    "#     data['most_common_campaigns_count_comm'] = get_feature_most_common(campaigns, 'count_comm', -1)\n",
    "    \n",
    "#     data['total_campaigns_channel'] = get_feature_total(campaigns, 'channel')\n",
    "#     data['most_common_campaigns_channel'] = get_feature_most_common(campaigns, 'channel', '<unknown>')\n",
    "    \n",
    "#     data['total_campaigns_prod'] = get_feature_total(campaigns, 'prod')\n",
    "    data['most_common_campaigns_prod'] = get_feature_most_common(campaigns, 'prod', '<unknown>')\n",
    "    \n",
    "#     data['diff_campaigns_otkaz-agr_flg'] = get_feature_diff(campaigns, 'otkaz', 'agr_flg', -999)\n",
    "    \n",
    "    data['rate_campaigns_otkaz-count_comm'] = get_feature_rate(campaigns, 'otkaz', 'count_comm', -999)\n",
    "    data['rate_campaigns_agr_flg-count_comm'] = get_feature_rate(campaigns, 'agr_flg', 'count_comm', -999)\n",
    "    data['rate_campaigns_not_ring_up_flg-count_comm'] = get_feature_rate(campaigns, 'not_ring_up_flg', 'count_comm', -999)\n",
    "    data['rate_campaigns_ring_up_flg-count_comm'] = get_feature_rate(campaigns, 'ring_up_flg', 'count_comm', -999)\n",
    "    \n",
    "    del campaigns\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_deals(data):\n",
    "    \n",
    "    deals = pd.read_csv(INPUT_PATH / 'deals.csv')\n",
    "    \n",
    "    deals['crncy_cd'] = deals['crncy_cd'].fillna(-2)\n",
    "    deals['agrmnt_rate_active'] = deals['agrmnt_rate_active'].fillna(-2)\n",
    "    deals['agrmnt_rate_passive'] = deals['agrmnt_rate_passive'].fillna(-2)\n",
    "    deals['agrmnt_sum_rur'] = deals['agrmnt_sum_rur'].fillna(-2)\n",
    "    deals['prod_type_name'] = deals['prod_type_name'].fillna('<UNK>')\n",
    "    deals['argmnt_close_start_days'] = (pd.to_datetime(deals['agrmnt_close_dt']) - pd.to_datetime(deals['agrmnt_start_dt'])).dt.days.fillna(-2)\n",
    "    \n",
    "    data['total_deals'] = data['client_id'].map(deals.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_deals_crncy_cd'] = get_feature_total(deals, 'crncy_cd')\n",
    "#     data['most_common_deals_crncy_cd'] = get_feature_most_common(deals, 'crncy_cd', -1)\n",
    "    \n",
    "    data['total_deals_agrmnt_rate_active'] = get_feature_total(deals, 'agrmnt_rate_active')\n",
    "    data['max_deals_agrmnt_rate_active'] = get_feature_max(deals, 'agrmnt_rate_active', -1)\n",
    "    \n",
    "#     data['total_deals_agrmnt_rate_passive'] = get_feature_total(deals, 'agrmnt_rate_passive')\n",
    "    data['max_deals_agrmnt_rate_passive'] = get_feature_max(deals, 'agrmnt_rate_passive', -1)\n",
    "    \n",
    "    data['total_deals_agrmnt_sum_rur'] = get_feature_total(deals, 'agrmnt_sum_rur')\n",
    "    data['mean_deals_agrmnt_sum_rur'] = get_feature_mean(deals, 'agrmnt_sum_rur', -1)\n",
    "    data['std_deals_agrmnt_sum_rur'] = get_feature_std(deals, 'agrmnt_sum_rur', -1)\n",
    "    \n",
    "    data['total_deals_prod_type_name'] = get_feature_total(deals, 'prod_type_name')\n",
    "    data['most_common_deals_prod_type_name'] = get_feature_most_common(deals, 'prod_type_name', '<unknown>')\n",
    "    \n",
    "    data['total_deals_argmnt_close_start_days'] = get_feature_total(deals, 'argmnt_close_start_days')\n",
    "    data['max_deals_argmnt_close_start_days'] = get_feature_max(deals, 'argmnt_close_start_days', -1)\n",
    "#     data['min_deals_argmnt_close_start_days'] = get_feature_min(deals, 'argmnt_close_start_days', -1)\n",
    "    data['mean_deals_argmnt_close_start_days'] = get_feature_mean(deals, 'argmnt_close_start_days', -1)\n",
    "    data['std_deals_argmnt_close_start_days'] = get_feature_std(deals, 'argmnt_close_start_days', -1)\n",
    "    \n",
    "    del deals\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_payments(data):\n",
    "    \n",
    "    payments = pd.read_csv(INPUT_PATH / 'payments.csv')\n",
    "    \n",
    "    payments['day_dt'] = pd.to_datetime(payments['day_dt'])\n",
    "    \n",
    "    data['total_payments'] = data['client_id'].map(payments.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "    data['mean_payments_sum_rur'] = get_feature_mean(payments, 'sum_rur', -1)\n",
    "    data['std_payments_sum_rur'] = get_feature_std(payments, 'sum_rur', -1)\n",
    "    data['min_payments_sum_rur'] = get_feature_min(payments, 'sum_rur', -1)\n",
    "    data['max_payments_sum_rur'] = get_feature_max(payments, 'sum_rur', -1)\n",
    "    \n",
    "#     data['total_payments_pmnts_name'] = get_feature_total(payments, 'pmnts_name')\n",
    "#     data['most_common_payments_pmnts_name'] = get_feature_most_common(payments, 'pmnts_name', '<unknown>')\n",
    "    \n",
    "    # payments \n",
    "#     data['last_known_salary'] = data['client_id'].map(payments.groupby('client_id').apply(lambda x: x['sum_rur'].iloc[0])).fillna(-1)\n",
    "#     data['total_recieved_salary'] = data['client_id'].map(payments.groupby('client_id').apply(lambda x: x['sum_rur'].sum())).fillna(-1)\n",
    "    \n",
    "    data['timedelta_payments_day_dt'] = get_feature_timedelta(payments, 'day_dt')\n",
    "    \n",
    "    del payments\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_appl(data):\n",
    "    \n",
    "    appl = pd.read_csv(INPUT_PATH / 'appl.csv')\n",
    "    \n",
    "    appl['appl_stts_name_dc'] = appl['appl_stts_name_dc'].fillna('<UNK>')\n",
    "    appl['appl_sale_channel_name'] = appl['appl_sale_channel_name'].fillna('<UNK>')\n",
    "    appl['month_end_dt'] = pd.to_datetime(appl['month_end_dt'])\n",
    "    \n",
    "    data['total_appl'] = data['client_id'].map(appl.groupby('client_id').size()).fillna(0)\n",
    "    \n",
    "#     data['total_appl_prod_group_name'] = get_feature_total(appl, 'appl_prod_group_name')\n",
    "#     data['most_common_appl_prod_group_name'] = get_feature_most_common(appl, 'appl_prod_group_name', '<unknown>')\n",
    "    \n",
    "    data['total_appl_prod_type_name'] = get_feature_total(appl, 'appl_prod_type_name')\n",
    "    data['most_common_appl_prod_type_name'] = get_feature_most_common(appl, 'appl_prod_type_name', '<unknown>')\n",
    "    \n",
    "#     data['total_appl_stts_name_dc'] = get_feature_total(appl, 'appl_stts_name_dc')\n",
    "#     data['most_common_appl_stts_name_dc'] = get_feature_most_common(appl, 'appl_stts_name_dc', '<unknown>')\n",
    "    \n",
    "#     data['total_appl_sale_channel_name'] = get_feature_total(appl, 'appl_sale_channel_name')\n",
    "#     data['most_common_appl_sale_channel_name'] = get_feature_most_common(appl, 'appl_sale_channel_name', '<unknown>')\n",
    "    \n",
    "    data['timedelta_appl_month_end_dt'] = get_feature_timedelta(appl, 'month_end_dt')\n",
    "    \n",
    "    del appl\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_features_funnel(data):\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73c4f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py:187: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  call = lambda f, *a, **k: f(*a, **k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 s, sys: 721 ms, total: 33.2 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create features\n",
    "\n",
    "funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "\n",
    "data = funnel.copy()\n",
    "\n",
    "del funnel\n",
    "\n",
    "data = create_features_transactions(data)\n",
    "data = create_features_aum(data)\n",
    "data = create_features_balance(data)\n",
    "data = create_features_client(data)\n",
    "data = create_features_campaigns(data)\n",
    "data = create_features_deals(data)\n",
    "data = create_features_payments(data)\n",
    "data = create_features_appl(data)\n",
    "data = create_features_funnel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939940c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill_cols = ['gender', 'citizenship', 'education', 'job_type', 'most_common_txn_city', 'most_common_tsp_name', 'most_common_txn_comment_1', 'most_common_txn_comment_2']# 'most_common_txn_city', 'most_common_tsp_name', 'most_common_txn_comment_1', 'most_common_txn_comment_2']\n",
    "for c in data.columns:\n",
    "    col_type = data[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        data[c] = data[c].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20096d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = TARGET_COLUMNS + ['client_id'])\n",
    "Y = data[TARGET_COLUMNS[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f246c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ddbee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    os.mkdir(OUTPUT_PATH / 'models')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'models')\n",
    "    os.mkdir(OUTPUT_PATH / 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba54e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats =[]\n",
    "for c in X.columns:\n",
    "    col_type = X[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        X[c] = X[c].astype(str)\n",
    "        cat_feats.append(np.argwhere(X.columns == c)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed148a",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f6a20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from quick_hyperopt import quick_hyperopt\n",
    "# cb_params = quick_hyperopt(X, Y, 'cb', 10, cat_features = cat_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e3c4e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee941d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_train(X_train, Y_train, X_val, Y_val, i_fold=None, seed=None, params = None):\n",
    "    # prepare for train\n",
    "    \n",
    "    params = {\n",
    "              \"thread_count\":-1,\n",
    "              \"random_seed\": seed,\n",
    "#               \"one_hot_max_size\": 5\n",
    "#               \"learning_rate\": 0.01,\n",
    "#               \"boosting_type\":\"Plain\",\n",
    "#               \"leaf_estimation_iterations\":1,\n",
    "#               \"iterations\": 200,\n",
    "#               \"random_strength\": 2,\n",
    "#               \"depth\": 7,\n",
    "#               \"l2_leaf_reg\": 1,\n",
    "#               \"eval_metric\": 'F1',\n",
    "#               'verbose': 10\n",
    "#         'objective': 'quantile',\n",
    "              }\n",
    "    \n",
    "    \n",
    "    #model = LGBMRegressor(**params) # define model here\n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    \n",
    "    # Fit and save model\n",
    "    \n",
    "    if X_val is None:\n",
    "        model.fit(X_train, Y_train, verbose=False, cat_features=cat_feats)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train,   eval_set=(X_val, Y_val), early_stopping_rounds=500, verbose=False, cat_features=cat_feats)\n",
    "    #joblib.dump(model, OUTPUT_PATH / 'models' / f'catboost_{i_fold}_{seed}_{CURRENT_TIME}.pkl')\n",
    "    model.save_model(OUTPUT_PATH / 'models' / f'catboost_{i_fold}_{seed}_{CURRENT_TIME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75385232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 948, 1/5\n",
      "Seed: 534, 2/5\n",
      "Seed: 432, 3/5\n",
      "Seed: 597, 4/5\n",
      "Seed: 103, 5/5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof = np.zeros((X.shape[0], n_seed)) # cv_score\n",
    "seeds = []\n",
    "for i_seed in range(n_seed):\n",
    "    seed = FIXED_SEEDS[i_seed]\n",
    "    seed_everything(seed)\n",
    "\n",
    "    seeds.append(seed)\n",
    "    print('Seed: {}, {}/{}'.format(seed, i_seed + 1, n_seed))\n",
    "    \n",
    "    if n_fold != 1:\n",
    "        kf = KFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "        split_indexes = kf.split(X, Y)\n",
    "    else:\n",
    "        split_indexes = [train_test_split(np.arange(X.shape[0]), random_state=seed, shuffle = True)]\n",
    "    \n",
    "    for i_fold, (train_idx, val_idx) in enumerate(split_indexes):\n",
    "#         print(\"# Fold: {}/{} (seed: {}/{})\".format(i_fold + 1, n_fold, i_seed + 1, n_seed))\n",
    "\n",
    "        # dataset\n",
    "        X_train, Y_train = X.iloc[train_idx], Y[train_idx]\n",
    "        X_val, Y_val = X.iloc[val_idx], Y[val_idx]\n",
    "\n",
    "\n",
    "        # train\n",
    "        running_train(X_train, Y_train, X_val, Y_val, i_fold=i_fold, seed=seed)\n",
    "\n",
    "        # predict on oof\n",
    "#         print('predict on oof...', end='')\n",
    "        model = CatBoostClassifier(thread_count=-1)\n",
    "        model.load_model( OUTPUT_PATH / 'models' / f'catboost_{i_fold}_{seed}_{CURRENT_TIME}')\n",
    "\n",
    "        prediction = model.predict_proba(X_val)[:, 1]\n",
    "        #prediction = model.predict(X_val)\n",
    "        \n",
    "        oof[val_idx, i_seed] = prediction\n",
    "#         print('  done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_threshold = 0.16\n",
    "funnel = pd.read_csv(INPUT_PATH / 'funnel.csv')\n",
    "if n_fold != 1:\n",
    "    Y_predicted = (np.mean(oof, axis = 1) > prediction_threshold).astype(int)\n",
    "    Y_test = funnel[['client_id', 'sale_flg']].set_index('client_id')\n",
    "    test_funnel =  funnel.set_index('client_id')\n",
    "if n_fold == 1 and n_seed == 1:\n",
    "    Y_predicted = (prediction > prediction_threshold).astype(int)\n",
    "    Y_test = funnel[['client_id', 'sale_flg']].iloc[split_indexes[0][1]].set_index('client_id')\n",
    "    test_funnel = funnel.iloc[split_indexes[0][1]].set_index('client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddaa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir(OUTPUT_PATH / 'scoring')\n",
    "except:\n",
    "    shutil.rmtree(OUTPUT_PATH / 'scoring')\n",
    "    os.mkdir(OUTPUT_PATH / 'scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b29ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_score, private_score = local_scorer.get_score(test_funnel, Y_predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_precision = precision_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_recall = recall_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_f1 = f1_score(Y_test['sale_flg'], Y_predicted)\n",
    "print(f'Public ANIC {public_score} Private ANIC {private_score}')\n",
    "print(f'ANIC {1/3*public_score+ 2/3 * private_score}')\n",
    "print(f'Precision {validation_precision} | Recall {validation_recall} | F1 {validation_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0505c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public ANIC 5443.947418364507 Private ANIC 5826.64704507396\n",
      "ANIC 5699.080502837475\n",
      "Precision 0.5039475644272308 | Recall 0.961352657004831 | F1 0.6612587959343237\n"
     ]
    }
   ],
   "source": [
    "validation_precision = precision_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_recall = recall_score(Y_test['sale_flg'], Y_predicted)\n",
    "validation_f1 = f1_score(Y_test['sale_flg'], Y_predicted)\n",
    "print(f'Public ANIC {public_score} Private ANIC {private_score}')\n",
    "print(f'ANIC {1/3*public_score+ 2/3 * private_score}')\n",
    "print(f'Precision {validation_precision} | Recall {validation_recall} | F1 {validation_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec054b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21498, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b5a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21498,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_cb = np.mean(oof, axis=1)\n",
    "oof_cb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c7cb12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21498,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_lgb = np.load('oof_lgb.npy')\n",
    "oof_lgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6de516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oof_cb.npy', oof_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6d72c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21498, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be7bcc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1 , 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ,\n",
       "       0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31,\n",
       "       0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 101)[10:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74488316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.53s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.55s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.53s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# prediction_threshold = 0.16\n",
    "w_range = np.linspace(0, 1, 11)\n",
    "t_range = np.linspace(0, 1, 101)[10:40]\n",
    "results = []\n",
    "for w in w_range:\n",
    "    for t in tqdm(t_range):\n",
    "        Y_predicted = (w * oof_cb + (1 - w) * oof_lgb > t).astype(int)\n",
    "        public_score, private_score = local_scorer.get_score(test_funnel, Y_predicted, Y_test)\n",
    "        anic = public_score / 3 + private_score * 2 / 3\n",
    "        results.append((w, t, anic))\n",
    "    # validation_precision = precision_score(Y_test['sale_flg'], Y_predicted)\n",
    "    # validation_recall = recall_score(Y_test['sale_flg'], Y_predicted)\n",
    "    # validation_f1 = f1_score(Y_test['sale_flg'], Y_predicted)\n",
    "    # print(f'Public ANIC {public_score} Private ANIC {private_score}')\n",
    "    # print(f'ANIC {1/3*public_score+ 2/3 * private_score}')\n",
    "    # print(f'Precision {validation_precision} | Recall {validation_recall} | F1 {validation_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f8f5949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6000000000000001, 0.25, 5713.325276769933)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x: x[2], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ced2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2394836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_after_valid = False\n",
    "if retrain_after_valid:\n",
    "    running_train(X, Y, None, None, i_fold=-1, seed=4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e936fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.run.summary[\"validation_f1\"] = validation_f1\n",
    "    wandb.run.summary[\"anic\"] = 1/3*public_score+ 2/3 * private_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "186cb6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 5800.68066785\n"
     ]
    }
   ],
   "source": [
    "make_submission = True\n",
    "if make_submission:\n",
    "    public_anic = float(input())\n",
    "    wandb.run.summary[\"public_anic\"] = public_anic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8b3e0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3883<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.44MB of 0.44MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/idao-2021-finals/wandb/run-20210418_115452-1zt0rgyx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/idao-2021-finals/wandb/run-20210418_115452-1zt0rgyx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>validation_f1</td><td>0.66126</td></tr><tr><td>anic</td><td>5699.0805</td></tr><tr><td>public_anic</td><td>5800.68067</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">2021-04-18_11:54:51</strong>: <a href=\"https://wandb.ai/artkulak/idao-2021-finals/runs/1zt0rgyx\" target=\"_blank\">https://wandb.ai/artkulak/idao-2021-finals/runs/1zt0rgyx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if USE_WANDB:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
